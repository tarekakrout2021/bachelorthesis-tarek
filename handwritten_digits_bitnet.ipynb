{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "from torchvision.utils import save_image, make_grid\n",
    "from torch.optim import Adam\n",
    "from bitlinear158 import BitLinear158, BitLinear158Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a transofrm to apply to each datapoint\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "# download the MNIST datasets\n",
    "path = '~/datasets'\n",
    "train_dataset = MNIST(path, transform=transform, download=True)\n",
    "test_dataset  = MNIST(path, transform=transform, download=True)\n",
    "\n",
    "# create train and test dataloaders\n",
    "batch_size = 100\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_data = train_dataset.data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get 25 sample training images for visualization\n",
    "dataiter = iter(train_loader)\n",
    "image = next(dataiter)\n",
    "\n",
    "num_samples = 25\n",
    "sample_images = [image[0][i,0] for i in range(num_samples)] \n",
    "\n",
    "fig = plt.figure(figsize=(5, 5))\n",
    "grid = ImageGrid(fig, 111, nrows_ncols=(5, 5), axes_pad=0.1)\n",
    "\n",
    "for ax, im in zip(grid, sample_images):\n",
    "    ax.imshow(im, cmap='gray')\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim=784, hidden_dim=400, latent_dim=200, device=device):\n",
    "        super(VAE, self).__init__()\n",
    "\n",
    "        # encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            BitLinear158(input_dim, hidden_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            BitLinear158(hidden_dim, latent_dim),\n",
    "            nn.LeakyReLU(0.2)\n",
    "            )\n",
    "        \n",
    "        # latent mean and variance \n",
    "        self.mean_layer = BitLinear158(latent_dim, 2)\n",
    "        self.logvar_layer = BitLinear158(latent_dim, 2)\n",
    "        \n",
    "        # decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            BitLinear158(2, latent_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            BitLinear158(latent_dim, hidden_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            BitLinear158(hidden_dim, input_dim),\n",
    "            nn.Sigmoid()\n",
    "            )\n",
    "     \n",
    "    def encode(self, x):\n",
    "        x = self.encoder(x)\n",
    "        mean, logvar = self.mean_layer(x), self.logvar_layer(x)\n",
    "        return mean, logvar\n",
    "\n",
    "    def reparameterization(self, mean, var):\n",
    "        epsilon = torch.randn_like(var).to(device)      \n",
    "        z = mean + var*epsilon\n",
    "        return z\n",
    "\n",
    "    def decode(self, x):\n",
    "        return self.decoder(x)\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean, logvar = self.encode(x)\n",
    "        z = self.reparameterization(mean, logvar)\n",
    "        x_hat = self.decode(z)\n",
    "        return x_hat, mean, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VAE().to(device)\n",
    "optimizer = Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(x, x_hat, mean, log_var):\n",
    "    reproduction_loss = nn.functional.binary_cross_entropy(x_hat, x, reduction='sum')\n",
    "    KLD = - 0.5 * torch.sum(1+ log_var - mean.pow(2) - log_var.exp())\n",
    "\n",
    "    return reproduction_loss + KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dim = 784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, epochs, device):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        overall_loss = 0\n",
    "        for batch_idx, (x, _) in enumerate(train_loader):\n",
    "            x = x.view(batch_size, x_dim).to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            x_hat, mean, log_var = model(x)\n",
    "            loss = loss_function(x, x_hat, mean, log_var)\n",
    "            \n",
    "            overall_loss += loss.item()\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        print(\"\\tEpoch\", epoch + 1, \"\\tAverage Loss: \", overall_loss/n_data)\n",
    "    return overall_loss\n",
    "\n",
    "train(model, optimizer, epochs=50, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_to_inference(model):\n",
    "    \n",
    "    bitlinear_layers  = [(k, m) for k, m in model.named_modules() if type(m).__name__ == 'BitLinear158'] \n",
    "    for name, layer in bitlinear_layers:\n",
    "        layer.beta = 1 / layer.weight.abs().mean().clamp(min=1e-5)\n",
    "        layer.weight = nn.Parameter((layer.weight * layer.beta).round().clamp(-1, 1))\n",
    "        layer.weight.detach()\n",
    "        layer.weight.requires_grad = False\n",
    "        new_layer = BitLinear158Inference(layer.input_dim, layer.output_dim)  \n",
    "        new_layer.weight.data = layer.weight.data.clone()\n",
    "        new_layer.beta =  layer.beta\n",
    "        setattr(model, name, new_layer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_digit(mean, var):\n",
    "    z_sample = torch.tensor([[mean, var]], dtype=torch.float).to(device)\n",
    "    x_decoded = model.decode(z_sample)\n",
    "    digit = x_decoded.detach().cpu().reshape(28, 28) # reshape vector to 2d array\n",
    "    plt.imshow(digit, cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "generate_digit(20.8, 37.5), generate_digit(-8.3, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_latent_space(model, scale=1.0, n=25, digit_size=28, figsize=15):\n",
    "    # display a n*n 2D manifold of digits\n",
    "    figure = np.zeros((digit_size * n, digit_size * n))\n",
    "\n",
    "    # construct a grid \n",
    "    grid_x = np.linspace(-scale, scale, n)\n",
    "    grid_y = np.linspace(-scale, scale, n)[::-1]\n",
    "\n",
    "    for i, yi in enumerate(grid_y):\n",
    "        for j, xi in enumerate(grid_x):\n",
    "            z_sample = torch.tensor([[xi, yi]], dtype=torch.float).to(device)\n",
    "            x_decoded = model.decode(z_sample)\n",
    "            digit = x_decoded[0].detach().cpu().reshape(digit_size, digit_size)\n",
    "            figure[i * digit_size : (i + 1) * digit_size, j * digit_size : (j + 1) * digit_size,] = digit\n",
    "\n",
    "    plt.figure(figsize=(figsize, figsize))\n",
    "    plt.title('VAE Latent Space Visualization')\n",
    "    start_range = digit_size // 2\n",
    "    end_range = n * digit_size + start_range\n",
    "    pixel_range = np.arange(start_range, end_range, digit_size)\n",
    "    sample_range_x = np.round(grid_x, 1)\n",
    "    sample_range_y = np.round(grid_y, 1)\n",
    "    plt.xticks(pixel_range, sample_range_x)\n",
    "    plt.yticks(pixel_range, sample_range_y)\n",
    "    plt.xlabel(\"mean, z [0]\")\n",
    "    plt.ylabel(\"var, z [1]\")\n",
    "    plt.imshow(figure, cmap=\"Greys_r\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_latent_space(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_latent_space(model, scale=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
